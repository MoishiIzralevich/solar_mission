{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25af1969",
   "metadata": {},
   "source": [
    "import library and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31dd3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3993b",
   "metadata": {},
   "source": [
    "Randomly place the digit within a larger sized picture and add new label for the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a71ecb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(img, value, new_size):\n",
    "    raw_img = np.zeros((new_size,new_size))\n",
    "    img = img/255\n",
    "    \n",
    "    x_min, y_min = np.random.randint(new_size - img.shape[0]), np.random.randint(new_size - img.shape[0])\n",
    "    x_max, y_max = x_min + img.shape[0], y_min + img.shape[0]\n",
    "    \n",
    "    \n",
    "    x_center = x_min + (x_max-x_min)/2\n",
    "    y_center = y_min + (y_max-y_min)/2\n",
    "    \n",
    "    raw_img[x_min:x_max, y_min:y_max] = img\n",
    "    raw_img = np.reshape(raw_img, (1,new_size,new_size))\n",
    "    label = [int(value), np.array([x_center, y_center]).astype('float32')]\n",
    "    \n",
    "    return raw_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [build_data(img, value, 90) for img, value in zip(x_train[:40000], y_train[:40000])]\n",
    "test_data = [build_data(img, value, 90) for img, value in zip(x_train[40000:45000], y_train[40000:45000])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd8ff7",
   "metadata": {},
   "source": [
    "download images from new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b302eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in train_data:\n",
    "#     cv2.imwrite(f'path_to_download{count}.jpg', i[0][0])\n",
    "#     count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec5080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87d51cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d69bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork_OL_v2(\n",
      "  (conv0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=10000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (linear_x): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (linear_y): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (linear_all): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork_OL_v2(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_OL_v2, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 16, 3, padding=(2,2))\n",
    "        self.pool0 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(16, 16, 3, padding=(3,3))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(16*25*25, 256), \n",
    "             nn.ReLU(),\n",
    "        )\n",
    "        self.linear = nn.Linear(256, 10)\n",
    "        self.linear_x = nn.Linear(256, 1)\n",
    "        self.linear_y = nn.Linear(256, 1)\n",
    "        self.linear_all = nn.Linear(256, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = F.relu(self.pool0(x))\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        logits = self.linear(x)\n",
    "        centr = self.linear_all(x)\n",
    "        return logits, centr\n",
    "\n",
    "model = NeuralNetwork_OL_v2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8e899",
   "metadata": {},
   "source": [
    "build two loss functions, one for digit and the other for the center "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab73a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_mse = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "alpha = 100\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac41cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, loss_mse, optimizer, alpha, beta):\n",
    "    model.train() \n",
    "    size = len(train_dataloader.dataset)\n",
    "    \n",
    "    loss_dig_list = []\n",
    "    loss_center_list = []\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        X, y0, y1 = X, y[0], y[1]\n",
    "\n",
    "        y0_pred, y1_pred = model(X.float())\n",
    "        \n",
    "        loss = alpha*loss_fn(y0_pred, y0) + beta*loss_mse(y1_pred, y1.float())\n",
    "        loss_dig = loss_fn(y0_pred, y0)\n",
    "        loss_center = loss_mse(y1_pred, y1.float())\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            \n",
    "            loss_dig = loss_dig.item()\n",
    "            loss_center = loss_center.item()\n",
    "            \n",
    "            loss_dig_list.append(loss_dig)\n",
    "            loss_center_list.append(loss_center)\n",
    "            print(f\"MAIN loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(f\"Digit prediction loss: {loss_dig:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(f\"Coordinate prediction loss: {loss_center:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\"-----------\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90e105d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(dataloader, model, loss_fn, loss_mse, alpha=alpha, beta=beta):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, test_loss_y0, test_loss_y1, correct = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y0, y1 = X, y[0], y[1]\n",
    "            y0_pred, y1_pred = model(X.float())\n",
    "            test_loss += alpha*loss_fn(y0_pred, y0).item() + beta*loss_mse(y1_pred, y1.float()).item()\n",
    "            test_loss_y0 += loss_fn(y0_pred, y0).item()\n",
    "            test_loss_y1 += loss_mse(y1_pred, y1.float()).item()\n",
    "            \n",
    "            correct += (y0_pred.argmax(1) == y0).type(torch.float).sum().item() # only for digit predictions\n",
    "            \n",
    "    # average the loss and accuracy among all records used in the dataset\n",
    "    test_loss /= size\n",
    "    test_loss_y0 /= size\n",
    "    test_loss_y1 /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg digit loss: {test_loss_y0:>8f}, Avg coordinate loss: {test_loss_y1:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5830533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, loss_mse, optimizer, alpha=alpha, beta=beta)\n",
    "    test(test_dataloader, model, loss_fn, loss_mse, alpha=alpha, beta=beta)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53a7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '/home/george/new_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4133d7",
   "metadata": {},
   "source": [
    "predict value for random index from the test data and plot him"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e55eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y) = next(iter(test_dataloader))\n",
    "indx = np.random.randint(64)\n",
    "y_center_actual, x_center_actual = int(y[1][indx][0]), int(y[1][indx][1])\n",
    "\n",
    "digit_pred, center_pred = model(X.float())\n",
    "\n",
    "predicted_digit = np.argmax(digit_pred[indx].cpu().detach().numpy())\n",
    "\n",
    "predicted_x = int(center_pred[indx][0])\n",
    "predicted_y = int(center_pred[indx][1])\n",
    "\n",
    "plt.imshow(np.reshape(X[indx].cpu().numpy(), (90,90)), cmap=\"gray\")\n",
    "# plot the actual center in green\n",
    "plt.plot(x_center_actual, y_center_actual, \"og\", markersize=10)\n",
    "# plot the predicted center in orange\n",
    "plt.plot(predicted_y, predicted_x, \"oy\", markersize=10)\n",
    "plt.show()\n",
    "\n",
    "print(\"Image shape: \" + str(list(X[indx].cpu().numpy().shape)))\n",
    "print(\"Digit: \" + str(int(y[0][indx])))\n",
    "print(\"True Center (in green): ({},{})\".format(y_center_actual, x_center_actual))\n",
    "print(\"-------------------------------\")\n",
    "print(\"Predicted Digit: \"+str(predicted_digit))\n",
    "print(\"Predicted Center (in yellow): ({},{})\".format(str(predicted_x), str(predicted_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00ff5743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork_OL_v2(\n",
       "  (conv0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=10000, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (linear_x): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (linear_y): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (linear_all): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('path_to_upload/new_model2'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c484ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img, degree):\n",
    "    img = ndimage.rotate(img, degree, reshape=False)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adcd482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(img):\n",
    "    noise = np.random.normal(0, .1, img.shape)\n",
    "    new_img = img + noise\n",
    "    \n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add99f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_check_model(x_train, y_train):\n",
    "    rotate_test_data = [build_data(rotate(img, np.random.randint(35)), value, 90) for img, value in zip(x_train, y_train)]\n",
    "    rotate_dataloader = DataLoader(rotate_test_data, batch_size=64, shuffle=True)\n",
    "    check_model(rotate_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b82722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_and_check_model(x_train, y_train):\n",
    "    noise_test_data = [build_data(noise(img/255), value, 90) for img, value in zip(x_train, y_train)]\n",
    "    noise_dataloader = DataLoader(noise_test_data, batch_size=64, shuffle=True)\n",
    "    check_model(noise_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(dataloader):\n",
    "    test(dataloader, model, loss_fn, loss_mse, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8724c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
